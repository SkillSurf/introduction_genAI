{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning SDXL DreamBooth using AutoTrain\n",
        "Introduction to Generative AI Workshop\n",
        "\n",
        "Â© SkillSurf 2024\n",
        "\n",
        "# Part 1 - Training the pre-trained model\n",
        "\n",
        "This notebook was created using the reference notebook published by [HuggingFace](https://colab.research.google.com/github/huggingface/autotrain-advanced/blob/main/colabs/AutoTrain_Dreambooth.ipynb).\n",
        "- **Step 1** - Upload images to a folder named `images/`\n",
        "- **Step 2** - Choose a project name (optional)\n",
        "- **Step 3** - Update the prompt with a unique identifier (Choose a word that doesn't appear in dictionaries)\n",
        "- **Step 4** - Run all cells in order until training is complete\n",
        "\n",
        "For original notebook/code visit:https://github.com/huggingface/autotrain-advanced"
      ],
      "metadata": {
        "id": "cztJ0Ko14GSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing AutoTrain\n",
        "\n",
        "For training through Google Colab we will need the CLI version of AutoTrain installed as a Python package. Use pip to download and install the necessary dependancies and packages to the working environment."
      ],
      "metadata": {
        "id": "FX5Pi7cI5v_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install AutoTrain using pip\n",
        "import os\n",
        "!pip install -U autotrain-advanced"
      ],
      "metadata": {
        "id": "7XD-JgWr5vUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up a training session\n",
        "\n",
        "The following parameters are fed into the AutoTrain CLI command as hyper-parameters needed for model training. Select `stabilityai/stable-diffusion-xl-base-1.0` as the model name and continue with these defualt settings.\n",
        "\n",
        "Feel free to experiment with the learning rate and epochs.\n",
        "\n",
        "\n",
        "```{warning}\n",
        "Remember to use a Unique identifier in the prompt. This identifier can be any token not commonly found in a dictionary.\n",
        "```\n"
      ],
      "metadata": {
        "id": "7Vxde3Z2525r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "# Basic details\n",
        "project_name = 'skillsurfgenAI'\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "prompt = 'cartoon of a sks dog'\n",
        "\n",
        "# Hyper-parameters\n",
        "learning_rate = 1e-4\n",
        "num_steps = 500\n",
        "batch_size = 1\n",
        "gradient_accumulation = 4\n",
        "resolution = 1024\n",
        "use_8bit_adam = False\n",
        "use_xformers = False\n",
        "mixed_precision = \"fp16\"\n",
        "train_text_encoder = False\n",
        "disable_gradient_checkpointing = False\n",
        "\n",
        "# Set up environment variables\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes Colab can create unnecessary files which can throw erros when training. Run the following code to delete such files."
      ],
      "metadata": {
        "id": "OSFKJ_2Xgv39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to avoid errors\n",
        "!rmdir /content/images/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "34xLifo6gzKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below runs a CLI command with the variables set-up above. Running this will start training the model."
      ],
      "metadata": {
        "id": "G9MU0df5g6FX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt"
      },
      "outputs": [],
      "source": [
        "# Run the AutoTrain CLI command using parameteres given above\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model weights to Google Drive\n",
        "\n",
        "Now that we have trained the model for a long time, we don't want to lose the weights when we close the browser. So we can either download the folder with the `project name` from the file browser in Colab or we can save it to our Google Drive using the code below."
      ],
      "metadata": {
        "id": "9_JuQXWq6RmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive onto Colab Folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZCkhJ_bItpy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy session folder into a folder in the drive\n",
        "!cp -r /content/skillsurfGenAI /content/drive/MyDrive/Dreambooth"
      ],
      "metadata": {
        "id": "msx7E6b3vbrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Generating images\n",
        "\n",
        "Now that we have trained a large model, our resources have been occupied. We should free the occupied RAM and GPU RAM before generating images. To do that, restart the runtime session and proceed with the cells below."
      ],
      "metadata": {
        "id": "MQP4gjtN6h7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules and building the Stable Diffusion pipeline\n",
        "\n",
        "We have the model weights in our project folder. They are saved as `pytorch_lora_weights.safetensors`. Now we will use Diffusers Python package to do the inferencing."
      ],
      "metadata": {
        "id": "VlJWknUh6mMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LvIS7-7PcLT"
      },
      "outputs": [],
      "source": [
        "# Import the diffusion pipeline and PyTorch\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Set up model details (Enter the path of your project folder)\n",
        "prj_path = \"/content/skillsurfgenAI\"\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Create an instance of the pipeline\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Send the pipeline to the GPU and load the finetuned weights\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating images for your own prompt\n",
        "\n",
        "Finally, it's time to test out the finetuned model with our own prompts."
      ],
      "metadata": {
        "id": "E1cDfyXl6sFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your own script, make it longer to be more specific\n",
        "prompt = \"\"\"cartoon of a sks dog as a Jedi holding a lightsaber, Star Wars, hyper detailed background, character concept, full body, dynamic pose, intricate,\n",
        "            highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, square thumbnail, 4k, uhd,\n",
        "            art by artgerm and greg rutkowski and alphonse mucha\"\"\"\n",
        "\n",
        "# Create the image and save it\n",
        "seed = 42\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "image.save(f\"generated_image.png\")"
      ],
      "metadata": {
        "id": "RQTYnGgy2_xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) - Refining the generated images\n",
        "\n",
        "Diffusers package comes with a built-in refiner. It can upscale the generated images increasing their quality. But due to the free resource limitation in Google Colab, using the generator pipeline and the refiner together will use up all the available RAM and GPU RAM. So the following code cannot be run on Google Colab free version.\n",
        "\n",
        "However if you have purchased Colab computing units or have a good enough GPU on your local machine feel free to run this code."
      ],
      "metadata": {
        "id": "46059VC17zix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import refiner from Stable Diffusion\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "\n",
        "# Initialize refiner\n",
        "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "# Create new prompt\n",
        "prompt = \"cartoon of a sks dog riding a formula one race car, comic art, studio ghibli style\"\n",
        "\n",
        "# Generate new image\n",
        "seed = 42\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "\n",
        "# Refine the image\n",
        "image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "\n",
        "image.save(f\"refined_image.png\")"
      ],
      "metadata": {
        "id": "4L4wN3Sy744g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}